{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bc13506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "225b7c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 1. DATA PROCESSING FUNCTIONS\n",
    "###############################################################################\n",
    "\n",
    "def convert_labels_to_pm1(y):\n",
    "    \"\"\"Convert labels {0,1} to {-1,+1}.\"\"\"\n",
    "    return np.where(y == 0, -1, 1)\n",
    "\n",
    "def create_pool_and_test_sets(X, y, test_size=0.3):\n",
    "    \"\"\"Split X,y into pool and test sets.\"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "\n",
    "def create_stream(X_pool, seed=1):\n",
    "    \"\"\"Shuffle pool to create i.i.d. stream.\"\"\"\n",
    "    rng = np.random.RandomState(seed)\n",
    "    indices = np.arange(len(X_pool))\n",
    "    rng.shuffle(indices)\n",
    "    return X_pool[indices]\n",
    "\n",
    "def build_oracle_mapping(X_pool, y_pool_pm1):\n",
    "    \"\"\"Map each sample to its true label ±1.\"\"\"\n",
    "    return {tuple(x): label for x, label in zip(X_pool, y_pool_pm1)}\n",
    "\n",
    "def make_oracle_function(pool_map):\n",
    "    \"\"\"Return oracle function for querying labels.\"\"\"\n",
    "    def oracle(x):\n",
    "        return pool_map.get(tuple(x), +1)\n",
    "    return oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1736d01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 2. A² ACTIVE LEARNING IMPLEMENTATION\n",
    "###############################################################################\n",
    "\n",
    "class A2ActiveLearner:\n",
    "    \"\"\"\n",
    "    Simplified Python implementation of A² algorithm with safety checks.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learn_H_fn, delta_schedule):\n",
    "        self.learn_H_fn = learn_H_fn\n",
    "        self.delta_schedule = delta_schedule\n",
    "        self.H_current = None\n",
    "\n",
    "    def disagreement(self, X, H):\n",
    "        \"\"\"Return indices where hypotheses in H disagree (simplified).\"\"\"\n",
    "        n = len(X)\n",
    "        mask = np.random.rand(n) < 0.5\n",
    "        return np.where(mask)[0]\n",
    "\n",
    "    def process_stream(self, X_stream, oracle):\n",
    "        \"\"\"Main loop of A² over stream with safety checks for single-class.\"\"\"\n",
    "        n = len(X_stream)\n",
    "        queried_labels = []\n",
    "        queried_X = []\n",
    "\n",
    "        # Step 0: find a point that adds a second class\n",
    "        for idx in range(n):\n",
    "            x0 = X_stream[idx].reshape(1, -1)\n",
    "            y0 = np.array([oracle(X_stream[idx])])\n",
    "            if len(np.unique([y0[0]] + queried_labels)) > 1:\n",
    "                self.H_current = self.learn_H_fn(x0, y0)\n",
    "                queried_X.append(X_stream[idx])\n",
    "                queried_labels.append(y0[0])\n",
    "                start_idx = idx + 1\n",
    "                break\n",
    "        else:\n",
    "            # If no second class, train on first point\n",
    "            x0 = X_stream[0].reshape(1, -1)\n",
    "            y0 = np.array([oracle(X_stream[0])])\n",
    "            self.H_current = self.learn_H_fn(x0, y0)\n",
    "            queried_X.append(X_stream[0])\n",
    "            queried_labels.append(y0[0])\n",
    "            start_idx = 1\n",
    "\n",
    "        # Process the rest of the stream\n",
    "        for t in range(start_idx, n):\n",
    "            x_t = X_stream[t].reshape(1, -1)\n",
    "            disagree_idx = self.disagreement(x_t, [self.H_current])\n",
    "\n",
    "            if len(disagree_idx) > 0:\n",
    "                y_t = oracle(X_stream[t])\n",
    "                # Update only if at least two classes present\n",
    "                if len(np.unique(queried_labels + [y_t])) > 1:\n",
    "                    queried_X.append(X_stream[t])\n",
    "                    queried_labels.append(y_t)\n",
    "                    X_update = np.array(queried_X)\n",
    "                    y_update = np.array(queried_labels)\n",
    "                    self.H_current = self.learn_H_fn(X_update, y_update)\n",
    "\n",
    "        query_count = len(queried_labels)\n",
    "        return self.H_current, query_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa3e17b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 3. PASSIVE BASELINE\n",
    "###############################################################################\n",
    "\n",
    "def run_passive_baseline(X_pool, y_pool, n_labels, learn_H_fn):\n",
    "    \"\"\"Randomly select n_labels points and ensure at least 2 classes.\"\"\"\n",
    "    max_attempts = 10\n",
    "    for _ in range(max_attempts):\n",
    "        indices = np.random.choice(len(X_pool), size=n_labels, replace=False)\n",
    "        y_sample = y_pool[indices]\n",
    "        if len(np.unique(y_sample)) > 1:\n",
    "            X_sample = X_pool[indices]\n",
    "            return learn_H_fn(X_sample, y_sample)\n",
    "    # Si impossible, utiliser tout le pool\n",
    "    return learn_H_fn(X_pool, y_pool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98b81b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 4. EVALUATION\n",
    "###############################################################################\n",
    "\n",
    "def evaluate_models(h_active, h_passive, X_test, y_test):\n",
    "    \"\"\"Compute accuracy for active and passive models.\"\"\"\n",
    "    y_test_pm1 = convert_labels_to_pm1(y_test)\n",
    "    preds_active = h_active.predict(X_test)\n",
    "    preds_passive = h_passive.predict(X_test)\n",
    "    acc_active = accuracy_score(y_test_pm1, preds_active)\n",
    "    acc_passive = accuracy_score(y_test_pm1, preds_passive)\n",
    "    return acc_active, acc_passive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90d76ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 5. EXPERIMENT PIPELINE\n",
    "###############################################################################\n",
    "\n",
    "def run_experiment(\n",
    "    X, y, test_size=0.3, stream_seed=1,\n",
    "    learn_H_fn=None, delta_schedule=None\n",
    "):\n",
    "    \"\"\"Full experiment: data, A², baseline, evaluation.\"\"\"\n",
    "\n",
    "    # Step 1: Pool/test split\n",
    "    X_pool, X_test, y_pool, y_test = create_pool_and_test_sets(X, y, test_size)\n",
    "\n",
    "    # Step 2: Convert labels\n",
    "    y_pool_pm1 = convert_labels_to_pm1(y_pool)\n",
    "\n",
    "    # Step 3: Create stream\n",
    "    X_stream = create_stream(X_pool, stream_seed)\n",
    "\n",
    "    # Step 4: Build oracle\n",
    "    pool_map = build_oracle_mapping(X_pool, y_pool_pm1)\n",
    "    oracle = make_oracle_function(pool_map)\n",
    "\n",
    "    # Step 5: Run A² active learning\n",
    "    a2_learner = A2ActiveLearner(learn_H_fn, delta_schedule)\n",
    "    h_active, query_count = a2_learner.process_stream(X_stream, oracle)\n",
    "\n",
    "    # Step 6: Run passive baseline\n",
    "    h_passive = run_passive_baseline(np.array(X_pool), np.array(y_pool_pm1), query_count, learn_H_fn)\n",
    "\n",
    "    # Step 7: Evaluate\n",
    "    acc_active, acc_passive = evaluate_models(h_active, h_passive, X_test, y_test)\n",
    "\n",
    "    return {\n",
    "        \"acc_active\": acc_active,\n",
    "        \"acc_passive\": acc_passive,\n",
    "        \"queries\": query_count,\n",
    "        \"n_pool\": len(X_pool),\n",
    "        \"n_test\": len(X_test)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "047b4a3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of classes has to be greater than one; got 1 class",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m delta_schedule = \u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[32m0.05\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Run experiment\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m results = \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_syn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_syn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_seed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearn_H_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearn_H_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelta_schedule\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdelta_schedule\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRésultats A² sur données synthétiques :\u001b[39m\u001b[33m\"\u001b[39m, results)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(X, y, test_size, stream_seed, learn_H_fn, delta_schedule)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Step 5: Run A² active learning\u001b[39;00m\n\u001b[32m     25\u001b[39m a2_learner = A2ActiveLearner(learn_H_fn, delta_schedule)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m h_active, query_count = \u001b[43ma2_learner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moracle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Step 6: Run passive baseline\u001b[39;00m\n\u001b[32m     29\u001b[39m h_passive = run_passive_baseline(np.array(X_pool), np.array(y_pool_pm1), query_count, learn_H_fn)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mA2ActiveLearner.process_stream\u001b[39m\u001b[34m(self, X_stream, oracle)\u001b[39m\n\u001b[32m     35\u001b[39m x0 = X_stream[\u001b[32m0\u001b[39m].reshape(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n\u001b[32m     36\u001b[39m y0 = np.array([oracle(X_stream[\u001b[32m0\u001b[39m])])\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[38;5;28mself\u001b[39m.H_current = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlearn_H_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m queried_X.append(X_stream[\u001b[32m0\u001b[39m])\n\u001b[32m     39\u001b[39m queried_labels.append(y0[\u001b[32m0\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mlearn_H_fn\u001b[39m\u001b[34m(X, y)\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mlearn_H_fn\u001b[39m(X, y):\n\u001b[32m     15\u001b[39m     model = Perceptron(max_iter=\u001b[32m1000\u001b[39m, tol=\u001b[32m1e-3\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\damoi\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\damoi\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:932\u001b[39m, in \u001b[36mBaseSGDClassifier.fit\u001b[39m\u001b[34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[39m\n\u001b[32m    903\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Fit linear model with Stochastic Gradient Descent.\u001b[39;00m\n\u001b[32m    904\u001b[39m \n\u001b[32m    905\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    928\u001b[39m \u001b[33;03m    Returns an instance of self.\u001b[39;00m\n\u001b[32m    929\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    930\u001b[39m \u001b[38;5;28mself\u001b[39m._more_validate_params()\n\u001b[32m--> \u001b[39m\u001b[32m932\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m    \u001b[49m\u001b[43mintercept_init\u001b[49m\u001b[43m=\u001b[49m\u001b[43mintercept_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\damoi\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:719\u001b[39m, in \u001b[36mBaseSGDClassifier._fit\u001b[39m\u001b[34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[39m\n\u001b[32m    716\u001b[39m \u001b[38;5;66;03m# Clear iteration count for multiple call to fit.\u001b[39;00m\n\u001b[32m    717\u001b[39m \u001b[38;5;28mself\u001b[39m.t_ = \u001b[32m1.0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_partial_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    721\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    722\u001b[39m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    723\u001b[39m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mintercept_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    734\u001b[39m     \u001b[38;5;28mself\u001b[39m.tol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    735\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tol > -np.inf\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_iter_ == \u001b[38;5;28mself\u001b[39m.max_iter\n\u001b[32m    737\u001b[39m ):\n\u001b[32m    738\u001b[39m     warnings.warn(\n\u001b[32m    739\u001b[39m         (\n\u001b[32m    740\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mMaximum number of iteration reached before \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    744\u001b[39m         ConvergenceWarning,\n\u001b[32m    745\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\damoi\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py:663\u001b[39m, in \u001b[36mBaseSGDClassifier._partial_fit\u001b[39m\u001b[34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[39m\n\u001b[32m    653\u001b[39m     \u001b[38;5;28mself\u001b[39m._fit_binary(\n\u001b[32m    654\u001b[39m         X,\n\u001b[32m    655\u001b[39m         y,\n\u001b[32m   (...)\u001b[39m\u001b[32m    660\u001b[39m         max_iter=max_iter,\n\u001b[32m    661\u001b[39m     )\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m663\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    664\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe number of classes has to be greater than one; got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m class\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    665\u001b[39m         % n_classes\n\u001b[32m    666\u001b[39m     )\n\u001b[32m    668\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: The number of classes has to be greater than one; got 1 class"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# 6. EXAMPLE USAGE\n",
    "###############################################################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from sklearn.datasets import make_classification\n",
    "\n",
    "    # Synthetic dataset\n",
    "    X_syn, y_syn = make_classification(\n",
    "        n_samples=500, n_features=10, n_informative=5, n_redundant=2, n_classes=2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Simple learning function using Perceptron\n",
    "    def learn_H_fn(X, y):\n",
    "        model = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
    "        model.fit(X, y)\n",
    "        return model\n",
    "\n",
    "    # Simple delta schedule placeholder\n",
    "    delta_schedule = lambda t: 0.05\n",
    "\n",
    "    # Run experiment\n",
    "    results = run_experiment(\n",
    "        X_syn, y_syn,\n",
    "        test_size=0.3,\n",
    "        stream_seed=1,\n",
    "        learn_H_fn=learn_H_fn,\n",
    "        delta_schedule=delta_schedule\n",
    "    )\n",
    "\n",
    "    print(\"Résultats A² sur données synthétiques :\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
