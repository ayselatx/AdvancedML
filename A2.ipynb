{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c62fcb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification, load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873dbc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a773c35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class A2ActiveLearner:\n",
    "    def __init__(self, learn_H, delta_schedule):\n",
    "        self.learn_H = learn_H\n",
    "        self.delta_schedule = delta_schedule\n",
    "        self.S = []  # inferred labels (x, y_hat)\n",
    "        self.T = []  # queried true labels (x, y_true)\n",
    "        self.query_count = 0\n",
    "\n",
    "    @staticmethod\n",
    "    def empirical_error(h, dataset):\n",
    "        if len(dataset) == 0:\n",
    "            return 0.0\n",
    "        X = np.array([x for (x, y) in dataset])\n",
    "        y = np.array([y for (x, y) in dataset])\n",
    "        preds = h.predict(X)\n",
    "        return np.mean(preds != y)\n",
    "\n",
    "    def process_stream(self, X_stream, oracle):\n",
    "        self.S = []\n",
    "        self.T = []\n",
    "        self.query_count = 0\n",
    "\n",
    "        for n, x_n in enumerate(X_stream, start=1):\n",
    "            # Train candidate hypotheses for hat{y} = +1 and -1\n",
    "            h_pos = self.learn_H(self.S + [(x_n, +1)], self.T)\n",
    "            h_neg = self.learn_H(self.S + [(x_n, -1)], self.T)\n",
    "\n",
    "            err_pos = self.empirical_error(h_pos, self.S + self.T)\n",
    "            err_neg = self.empirical_error(h_neg, self.S + self.T)\n",
    "\n",
    "            Delta = self.delta_schedule(max(1, n - 1))\n",
    "\n",
    "            inferred_label = None\n",
    "            if err_neg - err_pos > Delta:\n",
    "                inferred_label = +1\n",
    "            elif err_pos - err_neg > Delta:\n",
    "                inferred_label = -1\n",
    "\n",
    "            if inferred_label is not None:\n",
    "                self.S.append((x_n, inferred_label))\n",
    "            else:\n",
    "                y_n = oracle(x_n)\n",
    "                self.T.append((x_n, y_n))\n",
    "                self.query_count += 1\n",
    "\n",
    "        # final hypothesis\n",
    "        h_final = self.learn_H(self.S, self.T)\n",
    "        return h_final, self.query_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102ed4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_H_fn(S, T):\n",
    "    data = S + T\n",
    "    if len(data) == 0:\n",
    "        class ConstantPred:\n",
    "            def predict(self, X):\n",
    "                X = np.asarray(X)\n",
    "                return np.ones(len(X), dtype=int)\n",
    "        return ConstantPred()\n",
    "    X = np.array([x for (x, y) in data])\n",
    "    y = np.array([y for (x, y) in data])\n",
    "    y_sklearn = np.where(y == -1, 0, 1)\n",
    "    unique = np.unique(y_sklearn)\n",
    "    if len(unique) == 1:\n",
    "        cls = unique[0]\n",
    "        mapped_output = -1 if cls == 0 else 1\n",
    "        class ConstantPredClass:\n",
    "            def __init__(self, mapped_output):\n",
    "                self.mapped_output = mapped_output\n",
    "            def predict(self, X):\n",
    "                X = np.asarray(X)\n",
    "                return np.full(len(X), self.mapped_output, dtype=int)\n",
    "        return ConstantPredClass(mapped_output)\n",
    "    clf = LogisticRegression(max_iter=100, solver='liblinear')\n",
    "    clf.fit(X, y_sklearn)\n",
    "    class SklearnWrapper:\n",
    "        def __init__(self, clf):\n",
    "            self.clf = clf\n",
    "        def predict(self, X):\n",
    "            X = np.asarray(X)\n",
    "            preds = self.clf.predict(X)\n",
    "            return np.where(preds == 0, -1, 1)\n",
    "    return SklearnWrapper(clf)\n",
    "\n",
    "def delta_schedule(n):\n",
    "    return 0.1 / math.sqrt(n)\n",
    "\n",
    "def run_passive_baseline(X_pool, y_pool, n_queries, learn_H):\n",
    "    if n_queries == 0:\n",
    "        class ConstantPred:\n",
    "            def predict(self, X):\n",
    "                X = np.asarray(X)\n",
    "                return np.ones(len(X), dtype=int)\n",
    "        return ConstantPred()\n",
    "    idx = np.random.choice(len(X_pool), size=n_queries, replace=False)\n",
    "    X_train = X_pool[idx]\n",
    "    y_train = y_pool[idx]\n",
    "    y_train_mapped = np.where(y_train == 0, -1, 1)\n",
    "    data = list(zip(X_train, y_train_mapped))\n",
    "    clf = learn_H(data, [])\n",
    "    return clf\n",
    "\n",
    "\n",
    "def prepare_data_for_A2(X, y, test_size=0.3, stream_seed=1):\n",
    "    y = np.array(y)\n",
    "\n",
    "    # séparation pool/test\n",
    "    X_pool, X_test, y_pool, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # création flux\n",
    "    rng = np.random.RandomState(stream_seed)\n",
    "    indices = np.arange(len(X_pool))\n",
    "    rng.shuffle(indices)\n",
    "    X_stream = X_pool[indices]\n",
    "\n",
    "    # conversion labels -> {-1, +1}\n",
    "    y_pool_mapped = np.where(y_pool == 0, -1, 1)\n",
    "\n",
    "    # copies utiles\n",
    "    X_pool_arr = np.array(X_pool)\n",
    "    y_pool_arr = np.array(y_pool)\n",
    "\n",
    "    # mapping pour l'oracle\n",
    "    pool_map = {tuple(x): label for x, label in zip(X_pool, y_pool_mapped)}\n",
    "\n",
    "    def oracle(x):\n",
    "        return pool_map.get(tuple(x), +1)\n",
    "\n",
    "    return {\n",
    "        \"X_stream\": X_stream,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "        \"X_pool_arr\": X_pool_arr,\n",
    "        \"y_pool_arr\": y_pool_arr,\n",
    "        \"oracle\": oracle\n",
    "    }\n",
    "\n",
    "\n",
    "def run_experiment(X, y, test_size=0.3, stream_seed=1):\n",
    "    \n",
    "    data = prepare_data_for_A2(X, y, test_size, stream_seed)\n",
    "\n",
    "    X_stream = data[\"X_stream\"]\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    X_pool_arr = data[\"X_pool_arr\"]\n",
    "    y_pool_arr = data[\"y_pool_arr\"]\n",
    "    oracle = data[\"oracle\"]\n",
    "\n",
    "    active = A2ActiveLearner(learn_H_fn, delta_schedule)\n",
    "    h_active, query_count = active.process_stream(X_stream, oracle)\n",
    "\n",
    "    h_passive = run_passive_baseline(X_pool_arr, y_pool_arr, query_count, learn_H_fn)\n",
    "\n",
    "    y_test_mapped = np.where(y_test == 0, -1, 1)\n",
    "    preds_active = h_active.predict(X_test)\n",
    "    preds_passive = h_passive.predict(X_test)\n",
    "\n",
    "    acc_active = accuracy_score(y_test_mapped, preds_active)\n",
    "    acc_passive = accuracy_score(y_test_mapped, preds_passive)\n",
    "\n",
    "    return {\n",
    "        \"acc_active\": acc_active,\n",
    "        \"acc_passive\": acc_passive,\n",
    "        \"queries\": query_count,\n",
    "        \"n_pool\": len(X_pool_arr),\n",
    "        \"n_test\": len(X_test)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e5fe7b",
   "metadata": {},
   "source": [
    "## Création de données synthétiques:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b3b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiments with reduced synthetic size for speed\n",
    "X_syn, y_syn = make_classification(n_samples=600, n_features=20, n_informative=10,\n",
    "                                   n_redundant=5, n_clusters_per_class=2, flip_y=0.05, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d8d9a5",
   "metadata": {},
   "source": [
    "## Importation de dataset : breast cancer \n",
    "\n",
    "*(https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35604273",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = load_breast_cancer()\n",
    "X_bc = bc.data\n",
    "y_bc = bc.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5659a7f0",
   "metadata": {},
   "source": [
    "## Run les algos : A² et Passif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a913779",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_syn = run_experiment(X_syn, y_syn, test_size=0.3, stream_seed=2)\n",
    "\n",
    "res_bc = run_experiment(X_bc, y_bc, test_size=0.3, stream_seed=3)\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame([\n",
    "    {\"dataset\": \"Synthetic\", \"acc_active\": res_syn[\"acc_active\"], \"acc_passive\": res_syn[\"acc_passive\"], \"queries\": res_syn[\"queries\"]},\n",
    "    {\"dataset\": \"BreastCancer\", \"acc_active\": res_bc[\"acc_active\"], \"acc_passive\": res_bc[\"acc_passive\"], \"queries\": res_bc[\"queries\"]},\n",
    "])\n",
    "\n",
    "print(\"Results summary:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde6af22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in results_df.iterrows():\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.title(f\"{row['dataset']} — Test accuracy (Active vs Passive)\")\n",
    "    plt.bar([0,1], [row['acc_active'], row['acc_passive']])\n",
    "    plt.xticks([0,1], ['A2 Active', 'Passive'])\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "try:\n",
    "    from caas_jupyter_tools import display_dataframe_to_user\n",
    "    display_dataframe_to_user(\"A2 vs Passive results\", results_df)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "results_df.to_csv(\"/mnt/data/a2_vs_passive_results.csv\", index=False)\n",
    "print(\"\\nA CSV with the results was saved at /mnt/data/a2_vs_passive_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
